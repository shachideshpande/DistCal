{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preliminary-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, shutil, copy, time, random\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southwest-aluminum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchuq.transform.basic\n"
     ]
    }
   ],
   "source": [
    "from torchuq.metric.interval import *\n",
    "from torchuq.metric import distribution, quantile, interval\n",
    "from torchuq.transform.naive import *\n",
    "from torchuq.transform.conformal import *\n",
    "from torchuq.transform.basic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bright-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = 200\n",
    "def generate_predictions(n_pred):\n",
    "    pred_distribution = Normal(loc=torch.linspace(0, 2, n_pred)[torch.randperm(n_pred)], scale=torch.ones(n_pred))\n",
    "    labels = pred_distribution.sample() \n",
    "\n",
    "    pred_point = distribution_to_point(pred_distribution, functional='mean') \n",
    "    pred_interval = distribution_to_interval(pred_distribution, confidence=0.9)\n",
    "    pred_quantile = distribution_to_quantile(pred_distribution, n_quantiles=10)\n",
    "    pred_quantile2 = distribution_to_quantile(pred_distribution, quantiles=torch.linspace(0, 1, 12)[1:-1].pow(3))   # Get a strange quantile choice to make sure things still work\n",
    "    pred_particle = distribution_to_particle(pred_distribution, n_particles=30)\n",
    "    pred_ensemble = {'point_1': pred_point, 'interval_1': pred_interval, 'quantile_1': pred_quantile} \n",
    "    \n",
    "    prediction_list = [pred_particle, pred_distribution, pred_point, pred_interval, pred_quantile, pred_quantile2, pred_ensemble]\n",
    "    prediction_type = ['particle', 'distribution', 'point', 'interval', 'quantile', 'quantile', 'ensemble']\n",
    "\n",
    "    return prediction_list, prediction_type, labels\n",
    "\n",
    "prediction_list, prediction_type, labels = generate_predictions(n_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-alias",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to check that score and iscore are indeed inverse of each other\n",
    "from torchuq.transform.conformal import _conformal_iscore_functions, _conformal_score_functions\n",
    "values = torch.linspace(1, 2, 100).view(-1, 1)\n",
    "\n",
    "for prediction, ptype in zip(prediction_list, prediction_type):\n",
    "    for i in range(2):\n",
    "        score_name = '%s_%d' % (ptype, i) \n",
    "        if score_name in _conformal_score_functions.keys():\n",
    "            reconstruction = _conformal_iscore_functions[score_name](prediction, _conformal_score_functions[score_name](prediction, values))\n",
    "            print(score_name, reconstruction.shape, (reconstruction - values).abs().sum().item())  # The shape should be [100, 200] and all the reconstruction error should be 0\n",
    "    \n",
    "# Test to check that iscore and score are indeed inverse of each other (other composition direction)\n",
    "values = torch.linspace(0, 1, 100).view(-1, 1)\n",
    "for prediction, ptype in zip(prediction_list, prediction_type):\n",
    "    for i in range(2):\n",
    "        score_name = '%s_%d' % (ptype, i) \n",
    "        if score_name in _conformal_score_functions.keys():\n",
    "            reconstruction = _conformal_score_functions[score_name](prediction, _conformal_iscore_functions[score_name](prediction, values))\n",
    "            print(score_name, reconstruction.shape, (reconstruction - values).abs().sum().item())  # The shape should be [100, 200] and all the reconstruction error should be 0\n",
    "            \n",
    "# Note that it is normal for the interval_1 to have large error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proprietary-collapse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "tensor([[0.134, 0.225, 0.497, 0.497, 0.497, 0.770, 0.770, 0.770, 0.952, 0.952],\n",
      "        [0.126, 0.217, 0.490, 0.490, 0.490, 0.762, 0.762, 0.762, 0.944, 0.944],\n",
      "        [0.173, 0.264, 0.537, 0.537, 0.537, 0.810, 0.810, 0.810, 0.991, 0.991],\n",
      "        [0.092, 0.183, 0.456, 0.456, 0.456, 0.728, 0.728, 0.728, 0.910, 0.910],\n",
      "        [0.162, 0.252, 0.525, 0.525, 0.525, 0.798, 0.798, 0.798, 0.980, 0.980]])\n",
      "tensor([[0.068, 0.159, 0.300, 0.300, 0.300, 0.573, 0.573, 0.573, 0.820, 0.820],\n",
      "        [0.092, 0.183, 0.388, 0.388, 0.388, 0.661, 0.661, 0.661, 0.877, 0.877],\n",
      "        [0.132, 0.223, 0.414, 0.414, 0.414, 0.687, 0.687, 0.687, 0.909, 0.909],\n",
      "        [0.023, 0.113, 0.247, 0.247, 0.247, 0.520, 0.520, 0.520, 0.771, 0.771],\n",
      "        [0.107, 0.198, 0.362, 0.362, 0.362, 0.635, 0.635, 0.635, 0.871, 0.871]])\n",
      "tensor([ 8, 10,  8, 10,  8]) tensor([10, 10, 10, 10, 10])\n",
      "tensor([6., 6., 6., 6., 6.])\n",
      "tensor([[-5.,  7.],\n",
      "        [-inf, inf],\n",
      "        [-3.,  9.],\n",
      "        [-inf, inf],\n",
      "        [-3.,  9.]])\n"
     ]
    }
   ],
   "source": [
    "# Step by step testing\n",
    "\n",
    "from torchuq.transform.conformal import _conformal_score_functions\n",
    "from torchuq.transform.conformal import _conformal_iscore_functions\n",
    "\n",
    "# pred_point[10:20] = pred_point[9]\n",
    "# labels[10:20] = labels[9]\n",
    "\n",
    "pred_point = torch.Tensor([1., 2., 3., 3., 3., 4., 4., 4., 6., 6.])\n",
    "labels = torch.zeros(len(pred_point))\n",
    "\n",
    "predictions = torch.Tensor([1., 2., 3., 3., 3.])\n",
    "\n",
    "score_func = _conformal_score_functions['point_0']\n",
    "iscore_func = _conformal_iscore_functions['point_0']\n",
    "val_scores = torch.sort(score_func(pred_point, labels).abs().flatten())[0]\n",
    "val_scores_ge = torch.linspace(0, 1, len(val_scores)+2)[:-1]  # Generate 0, 1/N+1, ..., N/N+1\n",
    "val_scores_geq = torch.linspace(0, 1, len(val_scores)+2)[:-1]\n",
    "print(len(val_scores))\n",
    "\n",
    "# Compute the quantiles of the non-conformity scores, and handle situations where the quantiles are identical. \n",
    "while True:\n",
    "    new_val_scores_ge = val_scores_ge.clone()\n",
    "    new_val_scores_ge[1:-1][val_scores[:-1] == val_scores[1:]] = val_scores_ge[2:][val_scores[:-1] == val_scores[1:]]\n",
    "    if (new_val_scores_ge - val_scores_ge).sum() == 0:\n",
    "        break\n",
    "    val_scores_ge = new_val_scores_ge\n",
    "\n",
    "val_scores_geq = val_scores_ge[:-1] + (val_scores_ge[1:] - val_scores_ge[:-1]).view(1, -1) * torch.rand(len(predictions)).view(-1, 1)\n",
    "val_scores_ge = val_scores_ge[1:].view(1, -1).repeat(len(predictions), 1)\n",
    "\n",
    "while True:\n",
    "    new_val_scores_geq = val_scores_geq.clone()\n",
    "    new_val_scores_geq[:, 1:][:, val_scores[:-1] == val_scores[1:]] = val_scores_geq[:, :-1][:, val_scores[:-1] == val_scores[1:]]\n",
    "    if (new_val_scores_geq - val_scores_geq).sum() == 0:\n",
    "        break\n",
    "    val_scores_geq = new_val_scores_geq\n",
    "\n",
    "\n",
    "# val_scores_ge[i] is 1/(N+1)#{n | A(x_n, y_n) < a}, if a > val_scores[i]\n",
    "# val_scores_geq[i] is 1/(N+1)#{n | A(x_n, y_n) < a} + U(0, 1)/(N+1)#{n | A(x_n, y_n) = a} if a = val_scores[i]\n",
    "\n",
    "confidence = 0.95\n",
    "coverage = 'exact'\n",
    "\n",
    "if coverage == 'exact':   # If coverage is exact, add U(0, 1)/(N+1)\n",
    "    noise = torch.rand(len(predictions), 1) / (len(val_scores) + 1)\n",
    "    val_scores_geq = val_scores_geq + noise\n",
    "    val_scores_ge = val_scores_ge + noise\n",
    "else:   # If coverage is up to 1/N accuracy, then add 1/(N+1)\n",
    "    val_scores_geq = val_scores_geq + 1/(len(val_scores) + 1)\n",
    "    val_scores_ge = val_scores_ge + 1/(len(val_scores) + 1)\n",
    "    \n",
    "torch.set_printoptions(precision=3)\n",
    "print(val_scores_ge)\n",
    "print(val_scores_geq)\n",
    "\n",
    "geq_index = (val_scores_geq <= confidence).type(torch.int32).sum(dim=1) \n",
    "ge_index = (val_scores_ge <= confidence).type(torch.int32).sum(dim=1) \n",
    "\n",
    "eps = 1e-5 \n",
    "torch.set_printoptions(precision=5)\n",
    "target_scores = torch.maximum((val_scores[ge_index.clamp(max=len(val_scores)-1)] - eps), val_scores[geq_index-1])\n",
    "y_ub = iscore_func(predictions, target_scores.view(1, -1)).flatten()\n",
    "y_lb = iscore_func(predictions, -target_scores.view(1, -1)).flatten()\n",
    "y_ub[ge_index > len(val_scores)-1] = float('inf')\n",
    "y_lb[ge_index > len(val_scores)-1] = -float('inf')\n",
    "\n",
    "result = torch.stack([y_lb, y_ub], axis=-1)\n",
    "\n",
    "print(ge_index, geq_index)\n",
    "\n",
    "print(target_scores)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "responsible-chuck",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0392, 0.0588, 0.0784,  ..., 0.9608, 0.9804, 1.0000],\n",
      "        [0.0392, 0.0588, 0.0784,  ..., 0.9608, 0.9804, 1.0000],\n",
      "        [0.0392, 0.0588, 0.0784,  ..., 0.9608, 0.9804, 1.0000],\n",
      "        ...,\n",
      "        [0.0392, 0.0588, 0.0784,  ..., 0.9608, 0.9804, 1.0000],\n",
      "        [0.0392, 0.0588, 0.0784,  ..., 0.9608, 0.9804, 1.0000],\n",
      "        [0.0392, 0.0588, 0.0784,  ..., 0.9608, 0.9804, 1.0000]])\n",
      "tensor([[0.0363, 0.0559, 0.0755,  ..., 0.9579, 0.9775, 0.9971],\n",
      "        [0.0319, 0.0515, 0.0711,  ..., 0.9534, 0.9730, 0.9927],\n",
      "        [0.0360, 0.0556, 0.0752,  ..., 0.9576, 0.9772, 0.9968],\n",
      "        ...,\n",
      "        [0.0318, 0.0514, 0.0710,  ..., 0.9534, 0.9730, 0.9926],\n",
      "        [0.0355, 0.0551, 0.0747,  ..., 0.9570, 0.9766, 0.9963],\n",
      "        [0.0349, 0.0545, 0.0741,  ..., 0.9565, 0.9761, 0.9957]])\n",
      "tensor([ 9,  9,  9,  9, 10,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10,  9, 10,  9,\n",
      "        10,  9,  9,  9,  9,  9,  9, 10,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9, 10,  9,  9,  9, 10,  9, 10,  9,  9,  9,  9,  9])\n",
      "tensor([[ 0.4103,  0.6604],\n",
      "        [ 0.4002,  0.6503],\n",
      "        [ 0.8749,  1.1251],\n",
      "        [ 0.5921,  0.8422],\n",
      "        [ 0.8143,  1.0645],\n",
      "        [ 0.6123,  0.8624],\n",
      "        [ 0.1376,  0.3877],\n",
      "        [ 0.5315,  0.7816],\n",
      "        [ 0.8446,  1.0948],\n",
      "        [ 0.7032,  0.9534],\n",
      "        [ 0.8648,  1.1150],\n",
      "        [ 0.4911,  0.7412],\n",
      "        [ 0.7436,  0.9938],\n",
      "        [ 0.5820,  0.8321],\n",
      "        [ 0.2891,  0.5392],\n",
      "        [ 0.4608,  0.7109],\n",
      "        [ 0.0163,  0.2665],\n",
      "        [ 0.8042,  1.0544],\n",
      "        [ 0.8345,  1.0847],\n",
      "        [ 0.2487,  0.4988],\n",
      "        [ 0.2992,  0.5493],\n",
      "        [ 0.3598,  0.6099],\n",
      "        [-0.0948,  0.1554],\n",
      "        [ 0.2689,  0.5190],\n",
      "        [ 0.0365,  0.2867],\n",
      "        [ 0.2588,  0.5089],\n",
      "        [ 0.7537,  1.0039],\n",
      "        [ 0.2083,  0.4584],\n",
      "        [ 0.3093,  0.5594],\n",
      "        [ 0.3699,  0.6200],\n",
      "        [ 0.0972,  0.3473],\n",
      "        [ 0.4406,  0.6907],\n",
      "        [-0.0847,  0.1655],\n",
      "        [ 0.4204,  0.6705],\n",
      "        [ 0.1578,  0.4079],\n",
      "        [ 0.6527,  0.9028],\n",
      "        [-0.0544,  0.1958],\n",
      "        [ 0.6325,  0.8826],\n",
      "        [ 0.2386,  0.4887],\n",
      "        [ 0.7234,  0.9736],\n",
      "        [ 0.6931,  0.9433],\n",
      "        [ 0.1073,  0.3574],\n",
      "        [-0.0039,  0.2463],\n",
      "        [ 0.6830,  0.9332],\n",
      "        [ 0.6729,  0.9231],\n",
      "        [ 0.6426,  0.8927],\n",
      "        [-0.0342,  0.2160],\n",
      "        [ 0.2184,  0.4685],\n",
      "        [ 0.5113,  0.7614],\n",
      "        [-0.1049,  0.1453]])\n"
     ]
    }
   ],
   "source": [
    "n_pred = 100\n",
    "\n",
    "from torchuq.transform.conformal import _conformal_score_functions, _conformal_iscore_functions, _concat_predictions\n",
    "from torchuq import _get_prediction_batch_shape\n",
    "class ConformalIntervalPredictor(ConformalBase):\n",
    "    def __init__(self, input_type='interval', coverage='exact', score_func=0, confidence=0.95, verbose=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            input_type: str, one of the regression input types\n",
    "            score_func: int, the score function to use. The index corresponds to the paper (cite). \n",
    "            coverage: the coverage can be 'exact' or '1/n'. If the coverage is exact, then the algorithm can output [-inf, +inf] intervals\n",
    "        \"\"\"\n",
    "        super(ConformalIntervalPredictor, self).__init__(input_type=input_type, score_func=score_func, verbose=verbose)\n",
    "        self.val_scores = None\n",
    "        \n",
    "        assert coverage == 'exact' or coverage == '1/n' or coverage == '1/N', \"Coverage can only be 'exact' or '1/N'\"\n",
    "        self.coverage = coverage\n",
    "        self.confidence = confidence\n",
    "        \n",
    "    \n",
    "    def __call__(self, predictions, confidence=None):\n",
    "        \"\"\"\n",
    "        Input: \n",
    "            confidence: float, the confidence level of the prediction intervals. If None then uses the default confidence interval specified in the constructor \n",
    "        \"\"\"\n",
    "        if confidence is None:\n",
    "            confidence = self.confidence \n",
    "        assert confidence > 0 and confidence < 1., 'Confidence must be a number of (0, 1)'\n",
    "        \n",
    "        self.check_type(predictions) \n",
    "        self.to(predictions)\n",
    "        \n",
    "        score_func_name = '%s_%d' % (self.input_type, self.score_func)\n",
    "        score_func = _conformal_score_functions[score_func_name]\n",
    "        iscore_func = _conformal_iscore_functions[score_func_name]\n",
    "        \n",
    "        # Get the sorted non-conformity score on the validation set \n",
    "        test_shape = _get_prediction_batch_shape(predictions)\n",
    "        \n",
    "        val_scores = torch.sort(score_func(_concat_predictions[self.input_type](self.predictions), torch.cat(self.labels, dim=0)).abs().flatten())[0]\n",
    "        val_scores_ge = torch.linspace(0, 1, len(val_scores)+2, device=self.device)[:-1]  # Generate 0, 1/N+1, ..., N/N+1\n",
    "        val_scores_geq = torch.linspace(0, 1, len(val_scores)+2, device=self.device)[:-1]\n",
    "        \n",
    "        # Compute the quantiles of the non-conformity scores, and handle situations where the quantiles are identical. \n",
    "        while True:   # This iteration is for handling values with identical non-conformity score \n",
    "            new_val_scores_ge = val_scores_ge.clone()\n",
    "            new_val_scores_ge[1:-1][val_scores[:-1] == val_scores[1:]] = val_scores_ge[2:][val_scores[:-1] == val_scores[1:]]\n",
    "            if (new_val_scores_ge - val_scores_ge).sum() == 0:\n",
    "                break\n",
    "            val_scores_ge = new_val_scores_ge\n",
    "\n",
    "        val_scores_geq = val_scores_ge[:-1] + (val_scores_ge[1:] - val_scores_ge[:-1]).view(1, -1) * torch.rand(test_shape, device=self.device).view(-1, 1)\n",
    "        val_scores_ge = val_scores_ge[1:].view(1, -1).repeat(test_shape, 1)\n",
    "\n",
    "        while True:   # This iteration is for handling values with identical non-conformity score \n",
    "            new_val_scores_geq = val_scores_geq.clone()\n",
    "            new_val_scores_geq[:, 1:][:, val_scores[:-1] == val_scores[1:]] = val_scores_geq[:, :-1][:, val_scores[:-1] == val_scores[1:]]\n",
    "            if (new_val_scores_geq - val_scores_geq).sum() == 0:\n",
    "                break\n",
    "            val_scores_geq = new_val_scores_geq\n",
    "        \n",
    "\n",
    "        # Now we should have the following:\n",
    "        # val_scores_ge[i] is 1/(N+1)#{n | A(x_n, y_n) < a}, if a > val_scores[i]\n",
    "        # val_scores_geq[i] is 1/(N+1)#{n | A(x_n, y_n) < a} + U(0, 1)/(N+1)#{n | A(x_n, y_n) = a} if a = val_scores[i]\n",
    "        \n",
    "        if self.coverage == 'exact':   # If coverage is exact, add U(0, 1)/(N+1)\n",
    "            noise = torch.rand(test_shape, 1, device=self.device) / (len(val_scores) + 1)\n",
    "            val_scores_geq = val_scores_geq + noise\n",
    "            val_scores_ge = val_scores_ge + noise\n",
    "        else:   # If coverage is up to 1/N accuracy, then add 1/(N+1), we always under cover to achieve the smallest intervals \n",
    "            val_scores_geq = val_scores_geq + 1/(len(val_scores) + 1)\n",
    "            val_scores_ge = val_scores_ge + 1/(len(val_scores) + 1)\n",
    "        print(val_scores_ge)\n",
    "        print(val_scores_geq)\n",
    "        \n",
    "        geq_index = (val_scores_geq <= confidence).type(torch.int32).sum(dim=1) \n",
    "        ge_index = (val_scores_ge <= confidence).type(torch.int32).sum(dim=1)     # The score of which validation sample to use\n",
    "        \n",
    "        eps = 1e-5 \n",
    "        target_scores = torch.maximum((val_scores[ge_index.clamp(max=len(val_scores)-1)] - eps), val_scores[geq_index-1])\n",
    "        print(geq_index)\n",
    "        y_ub = iscore_func(predictions, target_scores.view(1, -1)).flatten()\n",
    "        y_lb = iscore_func(predictions, -target_scores.view(1, -1)).flatten()\n",
    "        \n",
    "        y_ub[(ge_index > len(val_scores)-1) | (geq_index > len(val_scores)-1)] = float('inf')\n",
    "        y_lb[(ge_index > len(val_scores)-1) | (geq_index > len(val_scores)-1)] = -float('inf')\n",
    "\n",
    "        result = torch.stack([y_lb, y_ub], axis=-1)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "calibrator = ConformalIntervalPredictor(input_type='point', coverage='1/N', confidence=0.2)\n",
    "predictions = torch.linspace(0, 1, n_pred)\n",
    "labels = predictions + torch.rand(n_pred) - 0.5 # torch.linspace(-1, 0.5, n_pred).clamp(min=0.0) + torch.linspace(-0.5, 1, n_pred).clamp(max=0.0)\n",
    "\n",
    "\n",
    "# predictions = torch.linspace(0, 1, n_pred)\n",
    "# labels = predictions.clone()\n",
    "\n",
    "perm = torch.randperm(n_pred)\n",
    "predictions = predictions[perm]\n",
    "labels = labels[perm]\n",
    "\n",
    "calibrator.train(predictions[:50], labels[:50])\n",
    "pred = calibrator(predictions[50:])\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-envelope",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
